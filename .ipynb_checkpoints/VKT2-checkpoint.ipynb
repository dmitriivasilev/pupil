{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm,trange\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import time\n",
    "import math\n",
    "import statistics as stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def crop_image(image):\n",
    "    \"\"\"\n",
    "    promts user to select region of interest of the image\n",
    "    \n",
    "    input: image to crop\n",
    "    \n",
    "    output: \n",
    "    - cropped image\n",
    "    - parameters of croping rectangle\n",
    "    \"\"\"\n",
    "    r = cv2.selectROI(image)\n",
    "    cropped = image[r[1]:(r[1]+r[3]),r[0]:(r[0]+r[2])]\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        cv2.destroyAllWindows()\n",
    "    \n",
    "    return cropped, r\n",
    "\n",
    "\n",
    "def callback(x):\n",
    "    \"\"\"\n",
    "    placeholder callback function\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "def stack2x2(img0,img1,img2,img3):\n",
    "    \"\"\"\n",
    "    stack 4 images 2x2\n",
    "    \n",
    "    input: 4 images to stack\n",
    "    \n",
    "    output: single image\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return np.vstack([np.hstack([img0,img1]),np.hstack([img2,img3])])\n",
    "    except:\n",
    "        error_message = str(img0.shape)+str(img1.shape)+str(img2.shape)+str(img3.shape)\n",
    "        raise NameError('PoEbaluNeHoschesh?\\t'+error_message)\n",
    "\n",
    "\n",
    "def adjust_parameres(cropped):\n",
    "    \"\"\"\n",
    "    promts user to select parameters for the model\n",
    "    \n",
    "    input: calibration image\n",
    "    output: \n",
    "    - gbkernel - kernel for gaussian blur\n",
    "    - threshval - threshold value\n",
    "    \"\"\"\n",
    "    \n",
    "    interblur = cropped.copy()\n",
    "\n",
    "    interthresh = cropped.copy()\n",
    "\n",
    "    interedged = cropped.copy()\n",
    "\n",
    "    ellipsed = cropped.copy()\n",
    "\n",
    "    result = stack2x2(interblur,interthresh,interedged,ellipsed)\n",
    "\n",
    "    # Create window\n",
    "    cv2.namedWindow('trying gui')\n",
    "    # Show an image in the window\n",
    "    cv2.imshow('trying gui', result)\n",
    "    # Add a slider\n",
    "    cv2.createTrackbar('Blur', 'trying gui', 1, 254, callback)\n",
    "    cv2.createTrackbar('Threshold', 'trying gui', 1, 255, callback)\n",
    "\n",
    "    # create switch for ON/OFF functionality\n",
    "    # switch = '0 : OFF \\n1 : ON'\n",
    "    # cv2.createTrackbar(switch, 'trying gui',0,1,callback)\n",
    "\n",
    "    while(True):\n",
    "        # Show 'em\n",
    "        cv2.imshow('trying gui',result)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "        gbkernel = cv2.getTrackbarPos('Blur','trying gui')\n",
    "        threshval = cv2.getTrackbarPos('Threshold','trying gui')\n",
    "\n",
    "        # Gaussian Blur requires odd number, correct for it\n",
    "        if gbkernel % 2 == 0:\n",
    "            gbkernel = gbkernel + 1\n",
    "\n",
    "        result,_,_ = find_pupil(cropped,gbkernel,threshval)\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    return gbkernel,threshval\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_pupil(cropped,gbkernel,threshval):\n",
    "    \n",
    "    interblur = cv2.GaussianBlur(cropped.copy(),(gbkernel,gbkernel),0)\n",
    "    _, interthresh = cv2.threshold(interblur.copy(),threshval,255,cv2.THRESH_BINARY)\n",
    "    interedged = cv2.Canny(interthresh.copy(),100,200)\n",
    "    \n",
    "    _, contours, _ = cv2.findContours(interedged, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    interedged = cv2.cvtColor(interedged,cv2.COLOR_GRAY2RGB);\n",
    "        \n",
    "        # Ellipse could only be fitted into a contour if it has at least 5 points. Thats why >4.\n",
    "    contours = [contour for contour in contours if len(contour)>4]\n",
    "        \n",
    "        # Get rid of obviously too small as well as too big contours.\n",
    "    contours = [contour for contour in contours if (cv2.contourArea(contour) > 2000) & (cv2.contourArea(contour) < 20000)]\n",
    "    \n",
    "        # Fit an ellipse into previously filtered contours.\n",
    "    ellipses = [cv2.fitEllipse(contour) for contour in contours]\n",
    "        \n",
    "        # Compute perimeter/area ratio of both original contours as well as fitted ellipses.\n",
    "        # If area is 0, assign arbitrary high value.\n",
    "        # Thus, we are defining the most \"circular\" out of all the fitted ellipses.\n",
    "        #\n",
    "    \n",
    "    if len(ellipses) == 0: # well, no money - no honey\n",
    "        #return copy of cropped image as ellipsed and zeros as pupil area and center\n",
    "        \n",
    "        ellipsed = cropped.copy()\n",
    "        \n",
    "        result = stack2x2(interblur,interthresh,interedged,ellipsed)\n",
    "        \n",
    "        pupil_area = 0\n",
    "        pupil_center = (0,0)\n",
    "        \n",
    "        cv2.putText(result,\"NO ELLIPSES\",(10,60), cv2.FONT_HERSHEY_SIMPLEX, 1.5,(0,0,255),1,cv2.LINE_AA)\n",
    "        \n",
    "        return result,pupil_area,pupil_center\n",
    "    \n",
    "    loss = np.asarray([abs(1-ellipse[1][0]/ellipse[1][1]) for ellipse in ellipses])\n",
    "    \n",
    "    #loss2 = np.asarray([(math.pi*((3*(ellipses[0][1][0] + ellipses[0][1][1])/2) - math.sqrt((3*ellipses[0][1][0]+ellipses[0][1][1])*(ellipses[0][1][0]+3*ellipses[0][1][1])/2)))/(math.pi / 4 * ellipses[0][1][0] * ellipses[0][1][1]) for x in ellipses])\n",
    "        \n",
    "        # Find the index of the minimal element of these perimeter/area ratios and pick the closest to a circle ellipse.\n",
    "        # If ellipse has a better ratio, than math is on our side.\n",
    "        # If not, we pray for the best by picking contour with a better ratio.\n",
    "        # This was implemented to minimize the probability of chosing wrong ellipse.\n",
    "    \n",
    "    center, axes, _ = ellipses[np.argmin(loss)]\n",
    "        \n",
    "    if abs(1-axes[0]/axes[1]) > eps:\n",
    "        #return copy of cropped image as ellipsed and zeros as pupil area and center\n",
    "        \n",
    "        ellipsed = cropped.copy()\n",
    "        \n",
    "        result = stack2x2(interblur,interthresh,interedged,ellipsed)\n",
    "        \n",
    "        pupil_area = 0\n",
    "        pupil_center = (0,0)\n",
    "        \n",
    "        cv2.putText(result,\"NO PUPPIL\",(10,60), cv2.FONT_HERSHEY_SIMPLEX, 1.5,(0,0,255),1,cv2.LINE_AA)\n",
    "        \n",
    "        return result,pupil_area,pupil_center\n",
    "    \n",
    "    ellipsed = cv2.ellipse(cropped.copy(),ellipses[np.argmin(loss)],(0,255,0),2)\n",
    "    \n",
    "    result = stack2x2(interblur,interthresh,interedged,ellipsed)\n",
    "    \n",
    "    pupil_area = math.pi / 4 * axes[0] * axes[1]\n",
    "    pupil_center = (center[0]+r[0],center[1]+r[3])    \n",
    "        \n",
    "    cv2.putText(result,'Area: '+ '{:.2f}'.format(pupil_area),(10,30), cv2.FONT_HERSHEY_SIMPLEX, 0.75,(0,0,170),1,cv2.LINE_AA)\n",
    "    cv2.putText(result,'Center: '+ '{:.2f}'.format(pupil_center[0])+' '+'{:.2f}'.format(pupil_center[1]),(10,50), cv2.FONT_HERSHEY_SIMPLEX, 0.75,(0,0,170),1,cv2.LINE_AA)\n",
    "    \n",
    "    return result,pupil_area,pupil_center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "eps = 0.20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|██▉                                                                          | 3389/90046 [01:19<34:00, 42.48it/s]"
     ]
    }
   ],
   "source": [
    "filename = 'toy_data/data.mj2'\n",
    "cap = cv2.VideoCapture(filename,0)\n",
    "length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    # Test for crop. Will be used later in code to crop the eye region.\n",
    "selection_set = False\n",
    "\n",
    "    #since we know the lenght of video we can init the size of arrays \n",
    "\n",
    "pupil_area = np.zeros(length)\n",
    "pupil_center = np.zeros([length,2])\n",
    "\n",
    "    # Start the processing. The while loop iterates over all the frames in given data set one by one.\n",
    "for i in trange(length):    \n",
    "        \n",
    "        # load the first frame\n",
    "    _, frame = cap.read()\n",
    "        \n",
    "        # Select the eye region on the first frame.\n",
    "    if not selection_set:\n",
    "        cropped,r = crop_image(frame)\n",
    "\n",
    "            #init placeholders for precessed images\n",
    "\n",
    "        interblur = cropped.copy()\n",
    "        interthresh = cropped.copy()\n",
    "\n",
    "        interedged = cropped.copy()\n",
    "        ellipsed = cropped.copy()\n",
    "            \n",
    "        gbkernel,threshval = adjust_parameres(cropped)\n",
    "            \n",
    "        selection_set = True\n",
    "        \n",
    "        \n",
    "        # Crop the frame according to region selected in the beginning.\n",
    "    cropped = frame[r[1]:(r[1]+r[3]),r[0]:(r[0]+r[2])]\n",
    "        \n",
    "    result,pupil_area[i],pupil_center[i] = find_pupil(cropped,gbkernel,threshval)\n",
    "        \n",
    "    cv2.imshow('result',result)\n",
    "        \n",
    "        # To stop video press q\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        np.save('test_area',pupil_area)\n",
    "        np.save('test_center',pupil_center)\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(''.format(1234567890.1234567890))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
