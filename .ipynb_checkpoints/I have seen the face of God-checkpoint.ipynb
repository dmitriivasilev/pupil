{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenCV Version : 3.4.0 \n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from tqdm import tqdm,trange\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import time\n",
    "import math\n",
    "from matplotlib import pyplot as plt\n",
    "print(\"OpenCV Version : %s \" % cv2.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 388.32it/s]\n"
     ]
    }
   ],
   "source": [
    "frames = []\n",
    "for x in trange(7):\n",
    "    image = cv2.imread('toy_data/halfblink'+str(x+1)+'.jpg',0)\n",
    "    frames.append(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pupil_area = []\n",
    "pupil_center = []\n",
    "\n",
    "# Load the video. 0 stays for binary (grayscaled, 1-channel) image loading.\n",
    "cap = cv2.VideoCapture('toy_data/data.mj2',0)\n",
    "\n",
    "# Test for crop. Will be used later in code to crop the eye region.\n",
    "selection_set = False\n",
    "\n",
    "# Start the processing. The while loop iterates over all the frames in given data set one by one.\n",
    "while(True):    \n",
    "    # Select the eye region on the first frame.\n",
    "    if not selection_set:\n",
    "        ret, frame = cap.read()\n",
    "        r = cv2.selectROI(frame)\n",
    "        selection_set = True\n",
    "        cv2.destroyAllWindows()\n",
    "    \n",
    "    # Load original frames.\n",
    "    _, frame = cap.read()\n",
    "        \n",
    "    # Crop the frame according to region selected in the beginning.\n",
    "    cropped = frame[r[1]:(r[1]+r[3]),r[0]:(r[0]+r[2])]\n",
    "    \n",
    "    ## Blur the frame. Arguments are handpicked.\n",
    "    blurred = cv2.GaussianBlur(cropped,(13,13),5)\n",
    "    \n",
    "    ## Get rid of most of lighter coloured pixels on the image. Arguments are handpicked.\n",
    "    _, thresholded = cv2.threshold(blurred,70,255,cv2.THRESH_BINARY)\n",
    "    \n",
    "    ## Detect the edges. Arguments are handpicked.\n",
    "    edged = cv2.Canny(thresholded,100,200)\n",
    "    \n",
    "    try:\n",
    "        _, contours, _ = cv2.findContours(edged, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        \n",
    "        # Ellipse could only be fitted into a contour if it has at least 5 points. Thats why >4.\n",
    "        contours = [contour for contour in contours if len(contour)>4]\n",
    "        \n",
    "        # Fit an ellipse into previously filtered contours.\n",
    "        ellipses = [cv2.fitEllipse(contour) for contour in contours]\n",
    "        \n",
    "        # Compute perimeter/area ratio. If area is 0, assign arbitrary high value.\n",
    "        # Thus, we are defining the most \"circular\" out of all the fitted ellipses.\n",
    "        loss = np.asarray([cv2.arcLength(cnt,True)/cv2.contourArea(cnt) if cv2.contourArea(cnt)!=0 else 100500 for cnt in contours])\n",
    "        \n",
    "        # Find the index of the minimal element of these perimeter/area ratios.\n",
    "        target_id = np.argmin(loss)\n",
    "        \n",
    "        # Draw an ellipse on the cropped image.\n",
    "        ellipsed = cv2.ellipse(cropped.copy(),ellipses[target_id],(0,255,0),2)\n",
    "        \n",
    "        # Plot lots of sexy rat's eyes.\n",
    "        result = np.vstack([np.hstack([cropped,blurred]),np.hstack([thresholded,ellipsed])])\n",
    "        \n",
    "        # Calculate area of fitted and position of it's center with respect to original image\n",
    "        center, axes, _ = ellipses[target_id]\n",
    "        ellarea = math.pi / 4 * axes[0] * axes[1]\n",
    "        \n",
    "        pupil_area.extend([ellarea])\n",
    "        pupil_center.extend([(center[0]+r[0],center[1]+r[3])])\n",
    "        \n",
    "        # Temporary solution for the case of eye's blink.\n",
    "    except:\n",
    "        error = cv2.putText(cropped.copy(),\"Achtung!\", (int(cropped.shape[0]/2),int(cropped.shape[1]/2)), cv2.FONT_HERSHEY_SIMPLEX, 2, 255)\n",
    "\n",
    "        result = np.vstack([np.hstack([cropped,blurred]),np.hstack([thresholded,error])])\n",
    "        \n",
    "        pupil_area.extend([0])\n",
    "        pupil_center.extend([(0,0)])\n",
    "        \n",
    "    # Pop-up all four steps \n",
    "    cv2.imshow('result',result)\n",
    "    \n",
    "    # To stop video press q\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"pupil_area\",pupil_area)\n",
    "np.save(\"pupil_center\",pupil_center)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C is OS\n",
      " Volume Serial Number is 5CB6-08E9\n",
      "\n",
      " Directory of C:\\Users\\proko\\Desktop\\pupil\n",
      "\n",
      "03/06/2018  07:36 PM    <DIR>          .\n",
      "03/06/2018  07:36 PM    <DIR>          ..\n",
      "03/05/2018  08:58 PM                68 .gitattributes\n",
      "03/05/2018  08:58 PM                 8 .gitignore\n",
      "03/06/2018  07:21 PM    <DIR>          .ipynb_checkpoints\n",
      "03/06/2018  07:30 PM             6,243 I have seen the face of God.ipynb\n",
      "03/05/2018  08:58 PM    <DIR>          notebooks\n",
      "03/06/2018  07:36 PM           221,432 pupil_area.npy\n",
      "03/06/2018  07:36 PM           442,784 pupil_center.npy\n",
      "03/06/2018  07:18 PM               341 README.md\n",
      "03/05/2018  08:58 PM                38 requirements.txt\n",
      "03/05/2018  09:13 PM    <DIR>          toy_data\n",
      "               7 File(s)        670,914 bytes\n",
      "               5 Dir(s)  88,804,204,544 bytes free\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "fig.add_subplot(111)\n",
    "\n",
    "# If we haven't already shown or saved the plot, then we need to\n",
    "# draw the figure first...\n",
    "fig.canvas.draw()\n",
    "\n",
    "# Now we can save it to a numpy array.\n",
    "data = np.fromstring(fig.canvas.tostring_rgb(), dtype=np.uint8, sep='')\n",
    "data = data.reshape(fig.canvas.get_width_height()[::-1] + (3,))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
