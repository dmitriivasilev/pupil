{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenCV Version : 3.4.0 \n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from tqdm import tqdm,trange\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import time \n",
    "from matplotlib import pyplot as plt\n",
    "print(\"OpenCV Version : %s \" % cv2.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90046\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cap = cv2.VideoCapture(\"data.mj2\")\n",
    "length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "print( length )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = cv2.selectROI(first[0])\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "    \n",
    "    # Crop image\n",
    "imCrop = first[0][int(r[1]):int(r[1]+r[3]), int(r[0]):int(r[0]+r[2])]\n",
    " \n",
    "    # Display cropped image\n",
    "cv2.imshow(\"Image\", imCrop)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:00<00:00, 85.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 6 imported frames\n"
     ]
    }
   ],
   "source": [
    "frames = []\n",
    "cropframes = []\n",
    "threshframes = []\n",
    "blurredframes = []\n",
    "cont = []\n",
    "\n",
    "cap = cv2.VideoCapture('data.mj2',0)\n",
    "\n",
    "for i in trange(6):\n",
    "            \n",
    "    ret, frame = cap.read()\n",
    "    frames.append(frame)\n",
    "    \n",
    "    imCrop = frames[i][int(r[1]):int(r[1]+r[3]), int(r[0]):int(r[0]+r[2])]\n",
    "    cropframes.append(imCrop)\n",
    "    \n",
    "    gaus = cv2.GaussianBlur(cropframes[i],(13,13),5)\n",
    "    blurredframes.append(gaus)\n",
    "    \n",
    "    retval, threshold = cv2.threshold(blurredframes[i],70,255,cv2.THRESH_BINARY)\n",
    "    threshframes.append(threshold)\n",
    "    \n",
    "    edges = cv2.Canny(threshframes[i],100,200)\n",
    "    cont.append(edges)\n",
    "    \n",
    "\n",
    "print('There are %d imported frames' %len(frames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cont[5]\n",
    "\n",
    "im2, contours, hierarchy = cv2.findContours(img.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "#\n",
    "\n",
    "cv2.imshow(\"Image\", img) \n",
    "cv2.waitKey(0)  \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "print(len(contours))\n",
    "image = cropframes[5].copy()\n",
    "cv2.drawContours(image, contours, -1, (0,155,0), 3)\n",
    "cv2.imshow(\"Game Boy Screen\", image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cropframes[5].copy()\n",
    "for i in range(len(contours)):\n",
    "    ellipse = cv2.fitEllipse(contours[2])\n",
    "    cv2.ellipse(image,ellipse,(0,255,0),2)\n",
    "    cv2.imshow(\"Image\", image) \n",
    "    cv2.waitKey(0)  \n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5 38.38477575778961\n",
      "19.5 17.071067690849304\n",
      "18.5 15.899494767189026\n",
      "42.0 457.8721445798874\n",
      "10476.5 392.09040224552155\n",
      "10430.5 389.7472552061081\n",
      "[0.06512998840413084, 1.1422835614700708, 1.1635589854199333, 0.09172866377039898, 26.71960328536622, 26.76221541184194]\n"
     ]
    }
   ],
   "source": [
    "ratio = []\n",
    "for x in range(len(contours)):\n",
    "    \n",
    "    perimeter = cv2.arcLength(contours[x],True)\n",
    "    area = cv2.contourArea(contours[x])\n",
    "    print(area, perimeter)\n",
    "    ratio.append(area/perimeter)\n",
    "\n",
    "print(ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(cont)):\n",
    "    cv2.imshow(\"Image\", cont[i]) \n",
    "    cv2.waitKey(0)  \n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.fitEllipse?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "(46.192996978759766, 41.905399322509766)\n",
      "(468, 241, 97, 80)\n",
      "(580, 780)\n",
      "[(421.80700302124023, 121.90539932250977), 2553.7041572585576]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import math\n",
    "img = cv2.imread('eye.jpg',0)\n",
    "\n",
    "r = cv2.selectROI(img)\n",
    "cv2.waitKey(0)  \n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "cropped = img[r[1]:(r[1]+r[3]),r[0]:(r[0]+r[2])]\n",
    "blurred = cv2.GaussianBlur(cropped,(13,13),5)\n",
    "_, thresholded = cv2.threshold(blurred,70,255,cv2.THRESH_BINARY)\n",
    "edged = cv2.Canny(thresholded,100,200)\n",
    "\n",
    "_, contours, _ = cv2.findContours(edged, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "print(len(contours))\n",
    "ellipsed = cv2.ellipse(cropped.copy(),cv2.fitEllipse(contours[1]),(0,255,0),2)\n",
    "\n",
    "center, axes, _ = cv2.fitEllipse(contours[1])\n",
    "print((center[0],center[1]))\n",
    "\n",
    "\n",
    "cv2.line(img,(0,0),(511,511),(255,0,0),5)\n",
    "\n",
    "\n",
    "\n",
    "cv2.imshow('asd',ellipsed)\n",
    "cv2.waitKey(0)  \n",
    "cv2.destroyAllWindows()\n",
    "ellarea = math.pi / 4 * axes[0] * axes[1]\n",
    "\n",
    "\n",
    "\n",
    "output = []\n",
    "print(r)\n",
    "print(img.shape)\n",
    "output.extend([(r[0]-center[0],center[1]+r[3]),ellarea])\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while(True):\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Our operations on the frame come here\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('frame',gray)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Test for crop. Will be used later in code to crop the eye region.\n",
    "selection_set = False\n",
    "\n",
    "# Start the processing. The while loop iterates over all the frames in given data set one by one.\n",
    "while(True):    \n",
    "    # Select the eye region on the first frame.\n",
    "    if not selection_set:\n",
    "        ret, frame = cap.read()\n",
    "        r = cv2.selectROI(frame)\n",
    "        selection_set = True\n",
    "        cv2.destroyAllWindows()\n",
    "    \n",
    "    # Load original frames.\n",
    "    _, frame = cap.read()\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Crop the frame according to region selected in the beginning.\n",
    "    cropped = gray[r[1]:(r[1]+r[3]),r[0]:(r[0]+r[2])]\n",
    "    \n",
    "    ## Blur the frame. Arguments are handpicked.\n",
    "    blurred = cv2.GaussianBlur(cropped,(13,13),5)\n",
    "    \n",
    "    ## Get rid of most of lighter coloured pixels on the image. Arguments are handpicked.\n",
    "    _, thresholded = cv2.threshold(blurred,70,255,cv2.THRESH_BINARY)\n",
    "    \n",
    "    ## Detect the edges. Arguments are handpicked.\n",
    "    edged = cv2.Canny(thresholded,100,200)\n",
    "    \n",
    "    try:\n",
    "        _, contours, _ = cv2.findContours(edged, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        \n",
    "        # Ellipse could only be fitted into a contour if it has at least 5 points. Thats why >4.\n",
    "        contours = [contour for contour in contours if len(contour)>4]\n",
    "        \n",
    "        # Fit an ellipse into previously filtered contours.\n",
    "        ellipses = [cv2.fitEllipse(contour) for contour in contours]\n",
    "        \n",
    "        # Compute perimeter/area ratio. If area is 0, assign arbitrary high value.\n",
    "        # Thus, we are defining the most \"circular\" out of all the fitted ellipses.\n",
    "        loss = np.asarray([cv2.arcLength(cnt,True)/cv2.contourArea(cnt) if cv2.contourArea(cnt)!=0 else 100500 for cnt in contours])\n",
    "        \n",
    "        # Find the index of the minimal element of these perimeter/area ratios.\n",
    "        target_id = np.argmin(loss)\n",
    "        \n",
    "        # Draw an ellipse on the cropped image.\n",
    "        ellipsed = cv2.ellipse(cropped.copy(),ellipses[target_id],(0,255,0),2)\n",
    "        \n",
    "        # Plot lots of sexy rat's eyes.\n",
    "        result = np.vstack([np.hstack([cropped,blurred]),np.hstack([thresholded,ellipsed])])\n",
    "        \n",
    "       \n",
    "        \n",
    "        # Temporary solution for the case of eye's blink.\n",
    "    except:\n",
    "        error = cv2.putText(cropped.copy(),\"Achtung!\", (int(cropped.shape[0]/2),int(cropped.shape[1]/2)), cv2.FONT_HERSHEY_SIMPLEX, 2, 255)\n",
    "\n",
    "        result = np.vstack([np.hstack([cropped,blurred]),np.hstack([thresholded,error])])\n",
    "        \n",
    "       \n",
    "\n",
    "    # Pop-up all four steps \n",
    "    cv2.imshow('result',result)\n",
    "    \n",
    "    # To stop video press q\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gg = cv2.line(img.copy(),(int(r[0]-center[0]),int(center[1]+r[3])),(int(r[0]-center[0]),int(center[1]+r[3])),(255,0,0),5)\n",
    "gg = cv2.ellipse(img,(int(r[0]-center[0]),int(center[1]+r[3])),(int(axes[0]),int(axes[1])),0,0,180,255,-1)\n",
    "cv2.imshow('asd',gg)\n",
    "cv2.waitKey(0)  \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
